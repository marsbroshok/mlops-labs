# Orchestrating model training and deployment with TFX and Cloud AI Platform

In this lab you will develop, deploy and run a TFX pipeline that uses Kubeflow Pipelines for orchestration and Cloud Dataflow and Cloud AI Platform for data processing, training, and deployment:


## Lab instructions

### Understanding the pipeline design.

The pipeline implements a typical TFX workflow as depicted on the below diagram:

![Lab 14 diagram](/images/lab-14-diagram.png).

1. Training data in the CSV format is ingested from the GCS location using *CsvExampleGen*. The URI to the data root is passed as a runtime parameter. The `CsvExampleGen` component splits the source data into training and evaluation splits and converts the data into the TFRecords format.
2. The *StatisticsGen* component generates statistics for both splits.
3. The *ImporterNode* component is used to bring the schema file. The locations of the schema file is passed as a runtime parameter. *This step is not depicted on the diagram*.
4. The *SchemaGen* component is used to autogenerate a new schema . This is done for tracking. The schema imported byt the *ImporterNode* will be used by the downstream components like *ExampleValidator*. But we also want to capture the autogenerated schema for future analysis.
5. The *ExampleValidator* component is used to validate generated examples against the imported schema
6. The *Transform* component is used to preprocess the data and generate the preprocessing graph. The location of the Python script with the preprocessing code is passed as a runtime parameter
7. The *Trainer* component is used to start an AI Platform Training job. The AI Platform Training job is configured to use a custom training container. The AI Platform Training configuration, which includes the URI of the custom training image, is a compile time setting. 
8. The *Evaluator* component is used to evaluate the trained model against the eval split
9. The *ModelValidate* component compares the model against a baseline. If this is the first run of the pipeline the model will be blessed regardless of an outcome of the evaluation. In subsequent runs, the baseline is a performance evaluation of the model from the previous run.
10. If the model trained by the pipeline was blessed, the model is deployed to AI Platform Prediction using the *Pusher* component. The configuration of AI Platform Prediction is a compile time setting.

The compile time settings, like the settings controlling AI Platform, and the default values for the runtime parameters are passed to the pipeline DSL using environment variables. This approach makes it easier to integrate the DSL with CI/CD workflow, which will be demonstrated in the `lab-03-tfx-cicd` lab.

The pipeline is configured to use a custom docker image as runtime environment for TFX components. The  image is a derivative of the standard [tensorflow/tfx:0.21.0 image](https://hub.docker.com/r/tensorflow/tfx). The same image is also used as a a training image used by **AI Platform Training**.

The custom image modifies the base image by adding the  the `transform_train.py` file that contains data transformation and training code and the `schema.pbtxt` that contains the custom schema developed in `lab-01-tfx-walkthrough`. The default values for the `module-file-uri` and `schema-file-uri` runtime parameters are set to point to these files. The default values of `module-file-uri` and `schema-file-uri` can be overwritten to point to other locations - e.g. in GCS - when creating a pipeline run.

### Configuring the environment settings

You will use a JupyterLab terminal as the primary interface during the lab. As noted in the previous section, the pipeline DSL retrieves the compile time settings from a set of environment variables. Before proceeding with the lab exercises you need to set these variables. If you used the default settings during the environment setup you don't need to modify the below commands. If you provided custom values for PREFIX, REGION, ZONE, or NAMESPACE update the commands accordingly:
```
export PROJECT_ID=$(gcloud config get-value core/project)
export PREFIX=$PROJECT_ID
export NAMESPACE=kubeflow
export GCP_REGION=us-central1
export ZONE=us-central1-a
export ARTIFACT_STORE_URI=gs://$PREFIX-artifact-store
export GCS_STAGING_PATH=${ARTIFACT_STORE_URI}/staging
export GKE_CLUSTER_NAME=$PREFIX-cluster
export DATA_ROOT_URI=gs://workshop-datasets/covertype/small

gcloud container clusters get-credentials $GKE_CLUSTER_NAME --zone $ZONE
export INVERSE_PROXY_HOSTNAME=$(kubectl describe configmap inverse-proxy-config -n $NAMESPACE | grep "googleusercontent.com")

export PIPELINE_NAME=tfx_covertype_continuous_training
export TFX_IMAGE=gcr.io/${PROJECT_ID}/custom_tfx:latest
export RUNTIME_VERSION=1.15
export PYTHON_VERSION=3.7
```



### Building and deploying the pipeline

You can build and upload the pipeline to the KFP environment in one step, using the `tfx pipeline create` command. The `tfx pipeline create` goes through the following steps:
- (Optional) Builds an image to host your components, 
- Compiles the pipeline DSL into a pipeline package 
- Uploads the pipeline package to the KFP environment.

As you are debugging the pipeline DSL, you may prefer to first use the `tfx pipeline compile` command, which only executes the compilation step. After the DSL compiles successfully you can use `tfx pipeline create` to go through all steps.

To compile the DSL
```
tfx pipeline compile --engine kubeflow --pipeline_path pipeline_dsl.py
```
This command creates a pipeline package named `${PIPELINE_NAME}.tar.gz`. The package containes the `pipeline.yaml` file that is a Kubeflow Pipelines YAML specification of the pipeline. 

To inspect the YAML specification extract the `pipeline.yaml` file from the tar archive and view the file in the JupyterLab editor.
```
tar xvf ${PIPELINE_NAME}.tar.gz
```

To build and upload the pipeline to the KFP environment use the `tfx pipeline create` command. Note that in this lab, the command is configured to use **Cloud Build** to build the image and push it to your project's **Container Registry**. This is set in the `build.yaml` file. TFX CLI uses [skaffold](https://skaffold.dev/) for the build step and `build.yaml` uses the build section of the full [`skaffold.yaml`](https://skaffold.dev/docs/design/config/) configuration.

Before executing the `tfx pipeline create` command, modify the `image` field of the `build.yaml` file so it references your project. 
```
SED_SCRIPT='s/\([[:blank:]]*image:[[:blank:]]*\).*/\1gcr\.io\/'$PROJECT_ID'\/custom_tfx/'
sed -i $SED_SCRIPT build.yaml
```

```
tfx pipeline create --engine kubeflow --pipeline_path pipeline_dsl.py --endpoint $INVERSE_PROXY_HOSTNAME
```



### Submitting and monitoring pipeline runs

After the pipeline has been deployed, you can trigger and monitor pipeline runs using **TFX CLI** or **KFP UI**.

To submit the pipeline run using **TFX CLI**:
```
tfx run create --pipeline_name $PIPELINE_NAME --endpoint $INVERSE_PROXY_HOSTNAME
```

To list all the active runs of the pipeline:
```
tfx run list --pipeline_name $PIPELINE_NAME --endpoint $INVERSE_PROXY_HOSTNAME
```

To retrieve the status of a given run:
```
tfx run status --pipeline_name $PIPELINE_NAME --run_id [YOUR_RUN_ID] --endpoint $INVERSE_PROXY_HOSTNAME
```
 To terminate a run:
 ```
 tfx run terminate --run_id [YOUR_RUN_ID] --endpoint $INVERSE_PROXY_HOSTNAME
 ```
### Deleting the pipeline
You can delete the pipeline from the KFP environment using the `tfx pipeline delete` command.
```
tfx pipeline delete --pipeline_name $PIPELINE_NAME --endpoint $INVERSE_PROXY_HOSTNAME
```

