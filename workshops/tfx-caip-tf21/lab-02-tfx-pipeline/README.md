# Orchestrating model training and deployment with TFX and Cloud AI Platform

In this lab you will develop, deploy and run a TFX pipeline that uses Kubeflow Pipelines for orchestration and Cloud Dataflow and Cloud AI Platform for data processing, training, and deployment:


## Lab scenario

You will be working with the [Covertype Data Set](https://github.com/jarokaz/mlops-labs/blob/master/datasets/covertype/README.md) dataset. 

The pipeline implements a typical TFX workflow as depicted on the below diagram:

![Lab 14 diagram](/images/lab-14-diagram.png).

The source data in a CSV file format is in the GCS bucket.

The TFX `ExampleGen`, `StatisticsGen`, `ExampleValidator`, `SchemaGen`, `Transform`, and `Evaluator` components use Cloud Dataflow as an execution engine. The `Trainer` and `Pusher` components use AI Platform Training and Prediction services.


## Lab setup

### AI Platform Notebook and KFP environment
Before proceeding with the lab, you must set up an **AI Platform Notebooks** instance and a **KFP** environment.

## Lab Exercises

You will use a JupyterLab terminal terminal as the primary interface during the lab. Before proceeding with the lab exercises configure a set of environment variables that reflect your lab environment. If you used the default settings during the environment setup you don't need to modify the below commands. If you provided custom values for PREFIX, REGION, ZONE, or NAMESPACE update the commands accordingly:
```
export PROJECT_ID=$(gcloud config get-value core/project)
export PREFIX=$PROJECT_ID
export NAMESPACE=kubeflow
export GCP_REGION=us-central1
export ZONE=us-central1-a
export ARTIFACT_STORE_URI=gs://$PREFIX-artifact-store
export GCS_STAGING_PATH=${ARTIFACT_STORE_URI}/staging
export GKE_CLUSTER_NAME=$PREFIX-cluster
export DATA_ROOT_URI=gs://workshop-datasets/covertype/full

gcloud container clusters get-credentials $GKE_CLUSTER_NAME --zone $ZONE
export INVERSE_PROXY_HOSTNAME=$(kubectl describe configmap inverse-proxy-config -n $NAMESPACE | grep "googleusercontent.com")
```

Follow the instructor who will walk you through the lab. The high level summary of the lab flow is as follows:

### Understanding the pipeline's DSL.

The pipeline uses a canonical TFX flow:
1. Training data in the CSV format is ingested from the GCS location using *CsvExampleGen*. The URI to the data root is passed as the pipeline's runtime parameter. The `CsvExampleGen` component splits the source data into training and evaluation splits and converts the data into the TFRecords format.
2. The *SchemaGen* component generates statistics for both splits.
3. The *ImporterNode* component is used to bring the schema file. The locations of the schema file is passed a runtime parameter.
4. The pipeline also generates the new schema from statistics. This is done for tracking. The imported schema will be used for the downstream components like *ExampleValidator*. But we also want to capture the autogenerated schema for future analysis.
5. The *ExampleValidator* component is used to validate generated examples against the imported schema
6. The *Transform* component is used to preprocess the data and generate the preprocessing graph. The location of the Python script with the preprocessing code is passed as a runtime parameter
7. The *Trainer* component is used to start an AI Platform Training job. The location of the Python script with the preprocessing code is passed as a runtime parameter. In the pipeline both data preprocessing and training code are packaged into the same Python file.
8. The *Evaluator* component is used to evaluate the trained model against the eval split
9. The *ModelValidate* component compares the model against the baseline. If this is the first run of the pipeline the model will be blessed regardless of the outcome of the evaluation
10. If the model trained by the pipeline was blessed, the model is deployed to AI Platform Prediction using the *Pusher* component.


The pipeline uses a custom docker image, which is a derivative of the [tensorflow/tfx:0.21.0 image](https://hub.docker.com/r/tensorflow/tfx), as a runtime execution environment for the pipeline's components. The same image is also used as a a training image used by **AI Platform Training**

The custom image modifies the base image by adding the  the `transform_train.py` file that contains data transformation and training code used by the pipeline's `Transform` and `Train` components.


### Building and deploying the pipeline
#### Creating the custom docker image
The first step is to build the custom docker image and push it to your project's **Container Registry**. You will use **Cloud Build** to build the image.

1. Create the Dockerfile describing the custom image
```
cat > Dockerfile << EOF
FROM tensorflow/tfx:0.21.0
RUN mkdir modules
COPY  transform_train.py modules/
EOF
```

2. Submit the **Cloud Build** job
```
IMAGE_NAME=tfx-image
TAG=latest
export TFX_IMAGE="gcr.io/${PROJECT_ID}/${IMAGE_NAME}:${TAG}"

gcloud builds submit --timeout 15m --tag ${TFX_IMAGE} .
```

#### Building and uploading the pipeline to the KFP environment
You can build and upload the pipeline in one step, using the `tfx pipeline create` command. The `tfx pipeline create` can optionally build an image to host your components, compiles the pipeline DSL into the pipeline package and uploads the pipeline package to the KFP environment.

However; as you are debugging the pipeline DSL you may prefer to use the `tfx pipeline compile` which only executes the compilation step.

```


tfx pipeline create --engine kubeflow --pipeline_path pipeline_dsl.py --endpoint $INVERSE_PROXY_HOSTNAME
```


The `tfx pipeline create` command compiles the pipeline's DSL into the KFP package file - `tfx_covertype_classifier_training.tar.gz` and uploads the package to the KFP environment. The package file contains the description of the pipeline in the YAML format. If you want to examine the file, extract from the tarball file and use the JupyterLab editor.

```
tar xvf tfx_covertype_classifier_training.tar.gz
```

The name of the extracted file is `pipeline.yaml`.


### Submitting and monitoring pipeline runs

After the pipeline has been deployed, you can trigger and monitor pipeline runs using **TFX CLI** or **KFP UI**.

To submit the pipeline run using **TFX CLI**:
```
tfx run create --pipeline_name $PIPELINE_NAME --endpoint $INVERSE_PROXY_HOSTNAME
```

To list all the active runs of the pipeline:
```
tfx run list --pipeline_name $PIPELINE_NAME --endpoint $INVERSE_PROXY_HOSTNAME
```

To retrieve the status of a given run:
```
tfx run status --pipeline_name $PIPELINE_NAME --run_id [YOUR_RUN_ID] --endpoint $INVERSE_PROXY_HOSTNAME
```
 To terminate a run:
 ```
 tfx run terminate --run_id [YOUR_RUN_ID] --endpoint $INVERSE_PROXY_HOSTNAME
 ```


